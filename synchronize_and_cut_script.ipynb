{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70917e38-54d0-430b-a8e1-082adb33d2ab",
   "metadata": {},
   "source": [
    "## We want to align an external video with the LSL-synced audio of the same event, then cut trial-sized segments based on LSL timing information. Finally, overlay the audio of each trial to their corresponding cut videos to check synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fde086-70ef-4f13-81a7-c016f6503f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "import subprocess\n",
    "from IPython.display import Audio\n",
    "import shign\n",
    "from shign.shign import ms_to_samples\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a504689-f3f0-425a-8d2c-549c5c0f62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths:\n",
    "video_file = \"external_video.mp4\" # Video to be synced\n",
    "csv_file = \"lsl_synced_long_audio_raw.csv\" # LSL synced audio in raw format\n",
    "\n",
    "# Output Names:\n",
    "extracted_video_audio = \"extracted_video_audio.wav\"\n",
    "lsl_synced_audio = \"lsl_synced_audio.wav\"\n",
    "aligned_video_audio = \"aligned_video_audio.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f8995-dddd-45a7-b0bc-8934d1d0fb58",
   "metadata": {},
   "source": [
    "## Inspecting the External Video for Sample Rate Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89949e3-c70a-416e-bd44-9de3a5c0e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the video:\n",
    "result = subprocess.run(\n",
    "    [\"ffmpeg\",\n",
    "     \"-hide_banner\",\n",
    "     \"-i\", video_file],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4815f2ae-c3b7-482a-b636-a065cc304367",
   "metadata": {},
   "source": [
    "## Extracting the Audio from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238eb38d-4648-4af1-89bb-bc11e5a3a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the audio from the video:\n",
    "subprocess.run([\n",
    "    \"ffmpeg\",              \n",
    "    \"-i\", video_file,      \n",
    "    \"-vn\",                      # Exclude the video stream\n",
    "    \"-acodec\", \"pcm_s16le\",\n",
    "    \"-ar\", \"44100\",             # Audio sample rate: 44100 Hz (We checked this above!)\n",
    "    \"-ac\", \"1\",                 # Converting the stereo audio to mono for consistency with the lsl_synced_audio\n",
    "    extracted_video_audio       \n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e28a7c-a38b-436f-bb53-b20ef0fab495",
   "metadata": {},
   "source": [
    "## Converting Raw LSL Audio in CSV File to WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c9653-d623-4a06-ad84-013545e90e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving raw lsl_synced_audio to .wav format:\n",
    "audio_data = pd.read_csv(csv_file, header=None)\n",
    "amplitude = audio_data[1].values.astype(np.int16)\n",
    "sample_rate = 16000                                     # Sample rate was 16 kHz\n",
    "write(lsl_synced_audio, sample_rate, amplitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c4ed55-204f-4dbe-b4ce-5d480bff92b1",
   "metadata": {},
   "source": [
    "## Align the Two Audio Tracks Using \"shign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79515d6-9b06-48b5-ac29-c3b457b22bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_synced_audio, sr_lsl = librosa.load(\"lsl_synced_audio.wav\", sr=None)\n",
    "extracted_audio, sr_ext = librosa.load(\"extracted_video_audio.wav\", sr=None)\n",
    "# Downsampling is a necessary step:\n",
    "extracted_audio_downsampled = librosa.resample(extracted_audio, orig_sr=sr_ext, target_sr=sr_lsl)\n",
    "sr_ext_downsampled = sr_lsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7d056-a9d5-49be-a6d0-008e146a8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting two audio before synchronization:\n",
    "plt.plot(lsl_synced_audio, label='lsl_audio')\n",
    "plt.plot(extracted_audio_downsampled, label='extracted_audio')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cf31e-c00e-4f9b-a384-5ea86309dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, extracted_audio_aligned, shift_ms = shign.shift_align(      # Saving shift_ms here to use it later\n",
    "    audio_a = lsl_synced_audio, \n",
    "    audio_b = extracted_audio_downsampled, \n",
    "    sr_a    = sr_lsl, \n",
    "    sr_b    = sr_ext_downsampled, \n",
    "    align_how = \"pad_and_crop_one_to_match_other\",      # Do not modify the lsl_audio\n",
    "    max_shift_sec = 300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81a8d8-fcf8-4e46-aa75-d5a26f57c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mismatch between two audio is {shift_ms/1000} seconds.\")\n",
    "\n",
    "# Negative means the second audio starts later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856e41d-f131-4bdf-88b3-286f581b036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lsl_synced_audio, label='lsl_audio')\n",
    "plt.plot(extracted_audio_aligned, label='extracted_audio_aligned')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bace24-def4-4de4-b03d-d36364c60fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lsl_synced_audio))\n",
    "Audio(lsl_synced_audio, rate=sr_lsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ec4ff-a3fc-4320-85eb-f15bf3136e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(extracted_audio_aligned))\n",
    "Audio(extracted_audio_aligned, rate=sr_ext_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8c792-7cd9-4c7d-8272-d754f81f8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the extracted_audio_aligned:\n",
    "write(\"extracted_audio_aligned.wav\", sr_ext_downsampled, extracted_audio_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3d51b-f0bc-4ad6-84b6-3beb363f8fea",
   "metadata": {},
   "source": [
    "## Aligning the External Video by Trimming (based on the computed \"shift_ms\" calculated from extracted audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab035106-0c0c-4587-bd06-ef6d3f6b3f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "video_file = \"external_video.mp4\"\n",
    "output_video = \"external_video_aligned.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84a59e-f7ec-42de-9fc3-046a08fc8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sample = ms_to_samples(abs(shift_ms), sr=sr_ext_downsampled)\n",
    "print(f\"extracted_audio_aligned starts at: {abs(shift_ms):.2f} milliseconds\")\n",
    "print(f\"extracted_audio_aligned starts at sample {start_sample:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c74821-b479-435e-8587-aa0a8fdab903",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_length_samples = len(extracted_audio_aligned)\n",
    "end_sample = start_sample + aligned_length_samples\n",
    "print(f\"extracted_audio_aligned ends at sample {end_sample:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7ab1a-23ee-4179-b98b-d78f4925953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the video cut times as seconds, using start and end samples and sample rate:\n",
    "start_time_sec = start_sample / sr_ext_downsampled\n",
    "end_time_sec = end_sample / sr_ext_downsampled\n",
    "print(f\"Aligned video starts at {start_time_sec:.2f}th second\")\n",
    "print(f\"Aligned video ends at {end_time_sec:.2f}th second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a740a-ef18-4ae1-b941-de0307c13834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the external_video_aligned using ffmpeg:\n",
    "print(f\"Trimming video from {start_time_sec:.2f}s to {end_time_sec:.2f}s...\")\n",
    "print(f\"Video length is {end_time_sec-start_time_sec:.2f} seconds...\")\n",
    "subprocess.run([\n",
    "    \"ffmpeg\",\n",
    "    \"-ss\", f\"{start_time_sec:.3f}\",    # Start time BEFORE -i ensures frame accuracy\n",
    "    \"-i\", video_file,                  \n",
    "    \"-to\", f\"{end_time_sec - start_time_sec:.3f}\",  # Duration after start\n",
    "    \"-c:v\", \"libx264\",                 # Re-encode video for frame accuracy\n",
    "    \"-c:a\", \"aac\",                     \n",
    "    \"-preset\", \"fast\",                 # Encoding speed optimization\n",
    "    \"-reset_timestamps\", \"1\",          # Reset timestamps after cutting\n",
    "    output_video                       \n",
    "], check=True)\n",
    "\n",
    "print(f\"Aligned video saved as {output_video}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f21d5f-787a-4dca-b6d0-d49b39c5d50d",
   "metadata": {},
   "source": [
    "## Computing the Trial Times from Each Trial's LSL-Synced Raw Audio in CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0cea4a-1b34-44d4-8236-00ec8d923836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the LSL synced audio .csv files of all trials:\n",
    "csv_folder = \"CSV_Files\"\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate over all CSV files in the folder:\n",
    "for file_name in os.listdir(csv_folder):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(csv_folder, file_name)\n",
    "            \n",
    "        # For each file:\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, header=None, names=[\"time_ms\", \"amplitude\"])\n",
    "                \n",
    "            # Get the start and end times\n",
    "            start_time = data[\"time_ms\"].iloc[1]\n",
    "            end_time = data[\"time_ms\"].iloc[-1]\n",
    "                \n",
    "            # Append the results to the list, including the filename\n",
    "            results.append({\n",
    "                \"file_name\": file_name,\n",
    "                \"start_time_ms\": start_time,\n",
    "                \"end_time_ms\": end_time\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {e}\")\n",
    "    \n",
    "# Convert results to DataFrame:\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame:\n",
    "output_filename = \"trial_times.csv\"\n",
    "results_df.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b08844c-61b4-44f4-ab8d-000fbce3c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the first 10 rows to inspect the accuracy of the times:\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3e2e8-863c-4751-9e78-4083d76da89a",
   "metadata": {},
   "source": [
    "## Mapping the Global Trial Start and End Times to Video Start and End Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed062e-b0c2-4eb8-83ed-07adb223e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and inputs\n",
    "lsl_audio_sr = sr_lsl\n",
    "extracted_audio_sr = sr_ext_downsampled\n",
    "csv_file = \"0_1_Mic_nominal_srate16000.csv\"  # raw lsl_synced_audio as a .csv file\n",
    "trial_times_file = \"trial_times.csv\" # previously saved trial start and end times\n",
    "mapped_output_file = \"mapped_event_markers.csv\" # output name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999ea8c-737b-41bd-8866-fa6c96ee8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "lsl_audio_raw = pd.read_csv(csv_file, header=None, names=[\"time_ms\", \"value\"])\n",
    "trial_times = pd.read_csv(trial_times_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7e9e5-469a-4af4-ab1e-4d6d523c8ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns for the results\n",
    "trial_times[\"lsl_sample_start\"] = None  # Sample number in lsl stream for start\n",
    "trial_times[\"lsl_sample_end\"] = None  # Sample number in lsl stream for end\n",
    "trial_times[\"video_time_start\"] = None  # Time in video (seconds) for start\n",
    "trial_times[\"video_time_end\"] = None  # Time in video (seconds) for end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19456cb5-5e24-48cc-a7ef-f31cb1278268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all rows\n",
    "for idx, row in trial_times.iterrows():\n",
    "    # Calculate lsl_sample_start by counting rows up to start_time_ms\n",
    "    lsl_sample_start = lsl_audio_raw[lsl_audio_raw[\"time_ms\"] <= row[\"start_time_ms\"]].shape[0]\n",
    "    \n",
    "    # Calculate lsl_sample_end by counting rows up to end_time_ms, similarly\n",
    "    lsl_sample_end = lsl_audio_raw[lsl_audio_raw[\"time_ms\"] <= row[\"end_time_ms\"]].shape[0]\n",
    "\n",
    "    # Calculate video start and end times based on sample rate (in seconds)\n",
    "    video_time_start = lsl_sample_start / lsl_audio_sr\n",
    "    video_time_end = lsl_sample_end / lsl_audio_sr\n",
    "\n",
    "    # Save results\n",
    "    trial_times.at[idx, \"lsl_sample_start\"] = lsl_sample_start\n",
    "    trial_times.at[idx, \"lsl_sample_end\"] = lsl_sample_end\n",
    "    trial_times.at[idx, \"video_time_start\"] = round(video_time_start, 6)\n",
    "    trial_times.at[idx, \"video_time_end\"] = round(video_time_end, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1af871-2f25-40c4-8f65-493fb1bda9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_times.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb533d-f96e-4669-89b7-e56192f39e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame in a different file:\n",
    "trial_times.to_csv(mapped_output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba581cb-8056-4e2c-a8b1-740db7c6ee9e",
   "metadata": {},
   "source": [
    "## Cutting the Trial Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63337d03-e2f6-40fa-9620-3b702c59db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data including the time markers to cut the aligned video:\n",
    "markers = pd.read_csv(\"mapped_event_markers.csv\")\n",
    "\n",
    "# Input video:\n",
    "input_video = \"external_video_aligned.mp4\"\n",
    "\n",
    "# Output folder:\n",
    "output_folder = \"cut_videos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904140d3-c266-42da-b5a1-8dcef8a5bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for i, row in markers.iterrows():\n",
    "    start_time = row[\"video_time_start\"]\n",
    "    end_time = row[\"video_time_end\"]\n",
    "    file_name = row[\"file_name\"]\n",
    "    \n",
    "    # Create an output file name based on the input filename (.mp4 instead of .csv):\n",
    "    output_file = os.path.join(output_folder, f\"{file_name.replace('.csv', '')}.mp4\")\n",
    "    \n",
    "    # Use FFmpeg to cut the video with accurate timestamps and no audio\n",
    "    ffmpeg_command = [\n",
    "    \"ffmpeg\",\n",
    "    \"-ss\", f\"{start_time:.3f}\",         \n",
    "    \"-i\", input_video,                  \n",
    "    \"-to\", f\"{end_time - start_time:.3f}\", \n",
    "    \"-c:v\", \"libx264\",                  \n",
    "    \"-an\",                              # Disable audio (for trial videos)\n",
    "    \"-preset\", \"fast\",                  # Faster encoding\n",
    "    \"-reset_timestamps\", \"1\",           # Reset timestamps globally\n",
    "    \"-filter_complex\", \n",
    "    \"[0:v]setpts=PTS-STARTPTS[v]\",      # Reset video PTS\n",
    "    \"-map\", \"[v]\",                      # Map video stream\n",
    "    \"-movflags\", \"+faststart\",          # Optimize for playback\n",
    "    output_file\n",
    "    ]\n",
    "    \n",
    "    # Execute the command using subprocess:\n",
    "    subprocess.run(ffmpeg_command, check=True)\n",
    "    print(f\"Segment saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9ba75-95cd-42ca-96f6-8dffa5b074ca",
   "metadata": {},
   "source": [
    "## (Optional) Overlaying the Audio of Each Trial to Their Cut Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8be65-e5a2-4597-8258-67d6ce542080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "current_folder = os.getcwd()\n",
    "video_folder = \"./cut_videos\" # folder including all the cut trial videos\n",
    "audio_folder = \"./audio_files\" # folder including all the trial audio files (names should match)\n",
    "output_folder = os.path.join(current_folder, \"audio_overlay\") # Output folder\n",
    "\n",
    "# Create the output folder if it doesn't exist:\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get sorted lists of video and audio files (only works if the names of the audio files and video files match)\n",
    "video_files = sorted([f for f in os.listdir(video_folder) if f.endswith(\".mp4\")])\n",
    "audio_files = sorted([f for f in os.listdir(audio_folder) if f.endswith(\".wav\")])\n",
    "\n",
    "for video_file, audio_file in zip(video_files, audio_files):\n",
    "    # Check if the first 10 characters of filenames match (as a second confirmation)\n",
    "    if video_file[:10] == audio_file[:10]:\n",
    "        video_path = os.path.join(video_folder, video_file)\n",
    "        audio_path = os.path.join(audio_folder, audio_file)\n",
    "        # Save with the same name as the original .mp4 file in the output folder\n",
    "        output_path = os.path.join(output_folder, video_file)\n",
    "        \n",
    "        ffmpeg_command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-i\", video_path,    \n",
    "            \"-i\", audio_path,     \n",
    "            \"-c:v\", \"copy\",       \n",
    "            \"-c:a\", \"aac\",        \n",
    "            \"-map\", \"0:v:0\",      # Map the first input's video\n",
    "            \"-map\", \"1:a:0\",      # Map the second input's audio\n",
    "            output_path           \n",
    "        ]\n",
    "        \n",
    "        # Run the FFmpeg command\n",
    "        print(f\"Overlaying audio for: {video_file} with {audio_file}\")\n",
    "        subprocess.run(ffmpeg_command)\n",
    "        print(f\"Saved with overlay audio: {output_path}\")\n",
    "    else:\n",
    "        print(f\"No matching audio found for video: {video_file}\")\n",
    "print(\"All videos processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
